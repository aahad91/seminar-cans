%% bare_conf.tex
%% V1.3
%% 2007/01/11
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.7 or later) with an IEEE conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%
%% File list of work: IEEEtran.cls, IEEEtran_HOWTO.pdf, bare_adv.tex,
%%                    bare_conf.tex, bare_jrnl.tex, bare_jrnl_compsoc.tex
%%*************************************************************************

% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. IEEE's font choices can trigger bugs that do  ***
% *** not appear when using other class files.                            ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



% Note that the a4paper option is mainly intended so that authors in
% countries using A4 can easily print to A4 and see how their papers will
% look in print - the typesetting of the document will not typically be
% affected with changes in paper size (but the bottom and side margins will).
% Use the testflow package mentioned above to verify correct handling of
% both paper sizes by the user's LaTeX system.
%
% Also note that the "draftcls" or "draftclsnofoot", not "draft", option
% should be used if it is desired that the figures are to be displayed in
% draft mode.
%
\documentclass[10pt, a4paper, conference]{IEEEtran}
% \documentclass[draftcls,conference]{IEEEtran}
% Add the compsoc option for Computer Society conferences.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/oberdiek/
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 4.0 (2003-05-27) and later if using hyperref.sty. cite.sty does
% not currently provide for hyperlinked citations.
% The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/cite/
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at: 
% http://www.ctan.org/tex-archive/macros/latex/required/graphics/
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found as epslatex.ps or
% epslatex.pdf at: http://www.ctan.org/tex-archive/info/
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
%\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty thesisis already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/


%\usepackage{mdwmath}
%\usepackage{mdwtab}
% Also highly recommended is Mark Wooding's extremely powerful MDW tools,
% especially mdwmath.sty and mdwtab.sty which are used to format equations
% and tables, respectively. The MDWtools set is already installed on most
% LaTeX systems. The lastest version and documentation is available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/mdwtools/


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.


%\usepackage{eqparbothesisx}
% Also of notable interest is Scott Pakin's eqparbox package for creating
% (automatically sized) equal width boxes - aka "natural width parboxes".
% Available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/eqparbox/





% *** SUBFIGURE PACKAGES ***
%\usepackage[tight,footnotesize]{subfigure}
% subfigure.sty was written by Steven Douglas Cochran. This package makes it
% easy to put subfigures in your figures. e.g., "Figure 1a and 1b". For IEEE
% work, it is a good idea to load it with the tight package option to reduce
% the amount of white space around the subfigures. subfigure.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at:
% http://www.ctan.org/tex-archive/obsolete/macros/latex/contrib/subfigure/
% subfigure.sty has been superceeded by subfig.sty.



%\usepackage[caption=false]{caption}
%\usepackage[font=footnotesize]{subfig}
% subfig.sty, also written by Steven Douglas Cochran, is the modern
% replacement for subfigure.sty. However, subfig.sty requires and
% automatically loads Axel Sommerfeldt's caption.sty which will override
% IEEEtran.cls handlithesisng of captions and this will result in nonIEEE style
% figure/table captions. To prevent this problem, be sure and preload
% caption.sty with its "caption=false" package option. This is will preserve
% IEEEtran.cls handing of captions. Version 1.3 (2005/06/28) and later 
% (recommended due to many improvements over 1.2) of subfig.sty supports
% the caption=false option directly:
%\usepackage[caption=false,font=footnotesize]{subfig}
%
% The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/
% The latest version and documentation of caption.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/caption/




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/



%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Documentation is contained in the stfloats.sty comments as well as in the
% presfull.pdf file. Do not use the stfloats baselinefloat ability as IEEE
% does not allow \baselineskip to stretch. Authors submitting work to the
% IEEE should note that IEEE rarely uses double column equations and
% that authors should try to avoid such use. Do not be tempted to use the
% cuted.sty or midfloat.sty packages (also by Sigitas Tolusis) as IEEE does
% not format its papers in such ways.




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/misc/
% Read the url.sty source comments for usage information. Basically,
% \url{my_url_here}.


\usepackage{listings}
\usepackage{paralist}
\usepackage{color}
\usepackage{subcaption}

\usepackage{booktabs}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{hyperref}

%\usepackage[disable]{todonotes}
\usepackage{todonotes}

\newcommand*\rot{\rotatebox{90}}
\newcommand*\rotninety{\rotatebox{90}}


\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}
\definecolor{light-gray}{gray}{0.95}

\lstset{ %
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} 
  basicstyle=\footnotesize\ttfamily,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  frame=single,	                   % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=4pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=1,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=2,	                   % sets default tabsize to 2 spaces
  title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}


% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor DevOps}


% MAP dummy commands that are only used in the working template (e.g. to-dos)
\usepackage{xargs}
\newcommandx{\unsure}[2][1=]{}
\newcommandx{\change}[2][1=]{}
\newcommandx{\info}[2][1=]{}
\newcommandx{\improvement}[2][1=]{}
\newcommandx{\thiswillnotshow}[2][1=]{}

%\pdfpagewidth=8.5in
%\pdfpageheight=11in

\newcommand{\todomp}[1]{\todo[color=blue!20,inline]{\textbf{MP:} #1}}
\newcommand{\todoss}[1]{\todo[color=green!20,inline]{\textbf{Stefan:} #1}}
\newcommand{\todocontribution}{\todo[color=red!60,inline]{looking for contributions}}
\newcommand{\fmhkn}[1]{\todo[color=red!10,inline]{\textbf{HK
:} #1}}

%\usepackage{draftwatermark}
%\SetWatermarkText{Draft}
%\SetWatermarkScale{1}


\begin{document}

% paper title
% can use linebreaks \\ within to get better formatting as desired

\title{AINFV: Analysis of Isolation (memory/packet) in Network Function Virtualization }
% 

%\author{\IEEEauthorblockN{Manuel Peuster}
%\IEEEauthorblockA{Paderborn University\\
%manuel.peuster@uni-paderborn.de}
%\and
%\IEEEauthorblockN{Holger Karl}
%\IEEEauthorblockA{Paderborn University\\
%  holger.karl@uni-paderborn.de}
%}

% author names and affiliations
\author{\IEEEauthorblockN{
    Abdul Ahad Ayaz\IEEEauthorrefmark{1},
  }
  \IEEEauthorblockA{\IEEEauthorrefmark{1}Paderborn University (ahad@mail.upb.de)
  }
  
}

% make the title area
\maketitle

\begin{abstract}
NFV (Network Function Virtualization) is a new way of defining a network with the help of software that was previously done with hardware middle-boxes. But there is isolation and performance overhead between NFV and hardware middle-boxes. The current approach is run network function in either VM or Container, this ensures isolation but at the cost of performance degradation. In this seminar paper, the NetBricks framework is introduced. This framework provides a new way of developing and running the network function. This paper further discussed isolation issues and performance overheads. A detailed comparison is provided between using the NetBricks framework and VMs/Containers.   
\end{abstract}



% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peer review papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle


\section{Introduction }
\label{sec:intro}

The starting days of networks, it was used to designed to send packets between two nodes. As the size of the network increased, technology evolved and many network services were introduced from time to time i.e. routing, forwarding, security, etc. Traditionally these network services were deployed using hardware middleboxes i.e. firewall, routers, etc. These traditional hardware middleboxes are in the market for a very long time and still serving their purposes. But there are disadvantages of using this approach, such as mentioned in \cite{Philippov2017}: 
$\bullet$inflexibility: unable to modify the network services, proprietary issue;$\bullet$Non-Scalability: one needs to buy the new middlebox if the load of the network increases for a certain period of time and the load stabilizes after some time, then the new middlebox is useless; and $\bullet$Cost: expensive in terms of  upgrading the network components by replacing old middleboxes with latest middleboxes to get the maximum throughput. These disadvantages encouraged the ETSI\cite{ETSI2012} (European Telecommunication Standards Institute) in 2012 and the idea of NFV (Network Function Virtualization) was proposed. The idea was to replace the hardware middleboxes with software-defined network services and deploy these network services as VM (Virtual Machine) on commodity servers. ETSI proposed that NFV will help the service providers as $\bullet$swift deployment of network services; $\bullet$comparatively cheap, by using the commodity servers; $\bullet$more flexibility, upgrading of network service is in software. As mentioned in \cite{Panda2017} NFV provides the blueprint of developing the network’s data plane, which allows the developer to program every packet forwarding in the network. Same in SDN (Software Defined Networking), which provides the blueprint of managing the control plane, i.e. allows a developer to define the custom routing, managing network failures, etc. NFV framework provides the following features\cite{Panda2017}:
\subsubsection{Multiplexing} NFV framework should ensure that the NF (Network Functions) should be hardware independent, this helps in scaling of NF without changing the hardware.
\subsubsection{Isolation} NF deployed in virtualized share the under the underlying hardware, NFV framework should ensure the memory and packet isolation without affecting the performance 
\subsubsection{High Performance} NF connected in series working as NF chains should have maximum throughput or equal to as of hardware middleboxes. NFV framework should ensure this throughput, as there is a major overhead of copying packets from one NF to others.
\subsubsection{Efficiency} Framework should ensure minimal hardware utilization as the aim of NFV is to utilize the commodity servers efficiently.
\subsubsection{Simplify NF Development} Framework should ensure the simplicity in development of NF, by separating the tasks into two categories i.e. user-defined functionality and preprocessing tasks. All of this should be automated. 
\subsubsection{Rapid Deployment} Framework should ensure the rapid deployment by production ready NFs (i.e. NF testing and deployment in the production environment on the go, to improve the performance). This saves a lot of time.
\subsection*{Problem Statment}
NFV framework has many advantages but these frameworks are still a long way from perfection in terms of development and deployment. For the development part as addressed in [Noval approach] main issue is the performance trade-off due to low-level programming and optimization issues. Isolation. No standard model is defined, thus every vendor has its programming model making NF operation complex to work in a multi-tenant network environment. For deployment, the current idea is to deploy NFs as VMs or Containers to give isolation as it is the main security concern. But at the cost of performance loss. The main idea is to deploy the NFs as a process instead of VMs or Containers.
\section{Background}
\subsection*{Requirements}
As discussed earlier, NFV purpose is to simplify the development and deployment of NFs without changing the functionality and performance offered by traditional middleboxes. As mentioned in \cite{Panda2017}, some requirements must be fulfilled:
\subsubsection{Performance} Framework should not take more than 10 seconds of a microsecond for processing packet. Single NF should be able to process 10-100Gbps of traffic. As the mentioned figures are equivalent to what we get with hardware middleboxes.  
\subsubsection{Efficiency} Deployment should be done using a single machine because deployment across multiple machines will result in poor resource utilization and performance loss.
\subsubsection{Chaining} Framework should be able to combine multiple NF called chaining i.e. NF1 to NF2...till NFn. Packet processing starts from NF1 to NFn. Fig1 shows the NF chain for processing web traffic.
\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/fig1}
	\caption{NF chain for serving web traffic}
	\cite{Panda2017}
	\label{key1}
\end{figure}
\subsubsection{Multi-vendor} NFV framework should support the multi-vendor NF to exists in a network, with security measures i.e. isolation.  
\subsubsection{Multi-tenant} In the cloud environment multiple tenants exist, sharing the virtual resource provided by the service provider. NF should be deployed in such a way that the deployment for one tenant should not affect the operation of other tenants. 

Mentioned requirements help in building well structured NFs and deployment ensuring the isolation. To get further insights into the NFV framework, NFV is divided into two parts, one part deals with the development model and the second part deals with the execution model.

\subsection{Development Model}
Throughput and latency are two major metrics affecting network performance. Throughput is packet processing in a given time whereas latency is time between sending and receiving of a packet. These two metrics depend on the number of things \cite{Philippov2017}i.e. context switching and copying, network card to cache copying, TLB (Translation Lookaside Buffer) misses and memory allocation. There are many libraries available for fast packet processing namely DPDK\cite{Corporation2014} and netmap etc. As mentioned in \cite{Panda2017} DPDK (Data Plane Development Kit) libraries provide fast packet processing mechanism by $\bullet$Using PMD (Poll-mode Driver) instead of depending on the CPU interrupts for acknowledgment of received packet; $\bullet$ assigning NIC (Network Interface Card) to single process instead of relying on kernel for NIC multiplexing; $\bullet$ provides the interface for connecting NIC directly to NF, instead of using intermediate elements (i.e. vSwitch) that required additional computation for packet movement. These libraries help in improving performance and developers to focus on optimization (i.e. how the packets should be batched). The use of vectorization, as proposed in \cite{Philippov2017}, VPP (Vector Packet Processing) allows the processing on vectors of packets (i.e. up to 256 packets can be read at once.) 
As discussed in \cite{Panda2017} The Click modular router \cite{Kohler2000} based on DPDK libraries, provides the abstraction to develop new NF in such a way by combining multiple packet processing elements. But does not define how packets flow between different elements. Click\cite{Martins2014} provides the limited functionality for customization. Hence for every new NF, developers have to re-write those elements from scratch, a lot of time is spent on optimizing the elements. Development model should be modular, some module with fixed functionality and common for all NFs, whereas other modules should be user-defined for specific functionality. A developer is responsible for optimizing the user-defined modules only.
\subsection{Execution Model}
Current practice is to deploy NFs in VMs or Containers and for communication vSwitch is used. VMs and Containers ensure the memory isolation (i.e. operation on one NF will not affect the other NF in a network). vSwitch allows the NFs to periodically use the NIC for sending and receiving of packets in networks or between NFs. But all this processing of packets is just copying of packets in network and every NF has its copy of packets that violates the packet isolation (i.e. at any point in time, only one NF should have access to that particular packet) and considerable hard to achieve. Above mentioned technologies have a greater influence on performance degradation. As mentioned in \cite{Panda2016}, comparing the single process with dedicated NIC, per-core throughput drops by 3x when processing 64B packets using Containers and up to 7x while using VMs. This performance degraded furthermore when NFs are chained, Containers are 7x slower compared to NF chained in a single process and VMs are up to 11x slower. Furthermore, NF chained single process is 6x faster than NF chained Containers or VMs, where each NF having its dedicated core. 
\subsection{Isolation}
Both packet and memory Isolation is the major challenge to achieve, as it directly affects the performance (i.e. latency and throughput). The main reason for this performance gap is: Firstly during packet processing, packets tend to cross the memory isolation barrier. Secondly the use of context switch that ensures that packet should cross core boundaries. These isolation issues can be catered as mentioned in \cite{Panda2016}: for memory isolation, instead of using VMs and Containers. Checks can be introduced both compile-time and run-time. For packet isolation, “ZCSI (Zero-Copy Software Isolation)” is proposed by the author in \cite{Panda2016} that ensures the “safe 0-copy” packet I/O between network functions. This is implemented using unique types\cite{Gordon}.
To address the issues of development and execution model, the author in \cite{Panda2016} proposed a solution called NetBricks. This solution showcased a different way of developing and executing network functions that contradict with the traditional approach. 

\section{Proposed Framework}
\subsection*{Overview}
NetBricks, a framework for developing and executing network functions on a single machine. It requires the re-writing of network function compatible with NetBricks development model. As mentioned in \cite{Panda2016}, it is not a limitation because of two reasons: $\bullet$ not enough development progress has been done for network functions; $\bullet$ NetBricks can also co-exists with the traditional network functions, at the cost of performance.
The proposed framework provides both a development and execution environment. For the development model, it helps developers to work on the high-level abstraction of packet processing tasks and allows user-defined programmability. The execution model uses safe language and runtimes to ensure memory isolation, whereas the current approach uses scheduling for performance isolation \cite{Panda2016}. Another important aspect to consider in the execution model is communication between network functions. Message passing [inter-process communication] must not be modified by network function to ensure packet isolation. To achieve this functionality, NetBricks uses “static checks” to avoid packet copying. The author in \cite{Panda2016} named this functionality as ZCSI (Zero-Copy Software Isolation). ZCSI allows achieving the memory and packet isolation as compared to VMs and Containers with no performance degradation. 

As discussed above, NetBricks is a complete package. In the section below, development model is explained in detailed, later section describes the execution model to deploy the network functions developed using development model
\subsection{Main Components of Development Model}
 As described in \cite{Panda2016}, NetBricks allows the developer to focus on the high-level programmability of network function. Network function programmability is divided into five sections: packet processing, bytestream processing, control flow, state management, and event scheduling.
\subsubsection{Packet Processing}
In NetBricks, packets structure consist of (a) stack of header; (b) the payload; (c) reference to any per-packet metadata \cite{Panda2016}. The header contains a structure that defines the length of a packet based on the functional computation of its contents. The payload is actual data carried by the packet. Metadata defines the internal communication within network function and it is customizable by the developer using user-defined functions. These user-defined functions are passed along with header structure and can access last deciphered header along with payload and related metadata. At the start, the header stack contains a “null” value, occupying zero byte space. The author provided the four packet operations as follows \cite{Panda2016}: 
\newline
\textbf{Parse:} This operation takes the header type and structure as an input. Later analyzes the payload accordingly by using header type and update the header stack. At the end header bytes are removed from the payload.  thesis
\newline
\textbf{Deparse:} This operation is applied on header stack, it removes the bottom header from the stack and returns it to the payload. 
\newline
\textbf{Transform:}  This operation implements the user-defined functions on header and payload, allows developer to modify the packet size (i.e. by adding or removing bytes to payload as mentioned in “parse”). It also allows to add and modify the metadata of the packet. 
\newline
\textbf{Filter:} This operation is used to remove packets to be dropped at a specific node. It is a boolean operation return either True or False. Filter operation is based on user-defined and it drops all the packets at the specific node when the user-defined function returns the false value.
\subsubsection{Bytestream Processing}
The main function of bytestream processing is to convert the bytes arrays into packets. User-defined functions are applied on the bytes arrays, In \cite{Panda2016}, the author provides the two bytestream operations as follows: 
\newline
\textbf{Window:} This operation takes four parameters as input i.e. window size, sliding increment, timeout, and a stream user-defined function. This operation is responsible for receiving and re-arranging the cached packets and create a stream. A user-defined function is called whenever there is enough data received to form a window of appropriate size or connection is closed or the timeout expires. Window operation can also forward all received packets without modifying them or it can drop all the packets and generate the modified byte array using packetize node. 
\newline
\textbf{Packetize:} This operation allows the conversion of byte arrays into packets. Providing the byte arrays and header stack, packetize converts and the data into packets and assign the relevant header.  For the Implementation of the operations as mentioned above author uses the TCP (i.e. TCP sequence number for re-arranging, FIN packets to check connection closing and packetize operation on a header by modifying the relevant header fields) \cite{Panda2016}.

\subsubsection{Control Flow}
Control flow deals with the branching required in network function chains. Branching is used to define the conditions i.e. re-routing the packets to specific port etc. Another purpose of branching is to move packets across cores for processing. To get the maximum performance, there should be minimum caching of data between cores. Control flow provides the developer the abstraction for re-routing the packets as desired i.e. by user-defined functions, port, address, etc. As mentioned above, control flow branching is useful while implementing the NF chains, it allows the developer to select which packet should be routed to the next network function. The author provides the three operations for control flow \cite{Panda2016} as follows: 
\newline
\textbf{Group By:} This operation allows the branching with-in NF and branching across NF chains. It takes two input: the number of groups for packet re-routing and user-defined function returning the packets with the ID of a group to which it belongs. The author also provided some pre-defined grouping functions based on criterion i.e. TCP flow.
\newline
\textbf{Shuffle:} This operation adds additional functionality to “Group By” operation i.e. branching is done based on cores. At “Runtime”, Group ID generated by shuffle is used to decide which core to be used for packet processing. Shuffle allows both user-defined and pre-defined grouping. The main point to consider is group id generated by the shuffle is not known at the “Compile time”. 
\newline
\textbf{Merge:} This operation provides a junction, where all the different branches can be merged i.e. all packets from different branches entering a junction and exist as a single group.

\subsubsection{State Management}
When data is processed across multiple cores, performance degradation can be observed. Due to communication between core i.e. cache coherence etc. Typically Developer program the network function to partition state and avoid cross-core access or allow minimal access when required without using partition state. NetBrick’s state management allows access across multiple cores. Within core accesses are synchronized but for cross-core accesses author proposed following options \cite{Panda2016}: $\bullet$ no-external-access i.e. one core for each partition; $\bullet$ bounded inconsistency\cite{Panda2017} i.e. where one core has write access to partition andSimple other cores only have read access; $\bullet$ strict consistency i.e. allows multi-read and multi-write access.

\subsubsection{Event Scheduling}
Event Scheduling allows the developer to create user-defined functions, that can be run repeatedly i.e. to monitor the NF and get the performance logs periodically, etc.
\subsection{Main Components of Execution Model}
NetBricks provides the execution environment to run the network function. This model ensures isolation and also deals with network function placement and scheduling \cite{Panda2016}.
\subsubsection*{Isolation}
\subsubsection{Memory Isolation}
Traditionally isolation is obtained by using VMs and Containers, at the cost of performance loss for simple network function. Considering the complex network function, this performance loss dominates the other factors. To tackle these performance degradations, NetBricks used a different approach to achieve isolation. It makes use of RUST \cite{TheRustTeam2016} safe language that ensures the type checks and LLVM \cite{Lattner} as a runtime. This combination of safe language and runtime achieves the memory isolation similar to that is obtained using the hardware MMU (Memory Management Unit). As mentioned in \cite{Panda2016}, safe language and runtime ensures the following: $\bullet$ disallow pointer arithmetic; $\bullet$ bound checking on array accesses i.e. preventing random memory accesses; $\bullet$ disallow accesses to null object i.e. preventing undefined behavior to ensure memory isolation; $\bullet$ type casts are safe. These above features can be achieved using high-level programming languages i.e. Java, C\#, etc, but these languages are not system friendly. 
\subsubsection{Packet Isolation}
The traditional mechanism is to send packets in a physical network, NFV follows the same footstep. Network function sent packets in the network by copying. This copying mechanism results in performance degradation of packet processing. NetBricks uses the unique types \cite{Gordon} instead of using the copying mechanism. As mentioned in \cite{Panda2016}, unique types are used to cater data races i.e. disallowing the simultaneous accesses to the same data. This approach is applied while implementing the network functions when network function sends a packet, sender function losses the accesses to that packet and only relevant network function should have accesses to that packet. This ensures packet isolation without any copying of packets.

Above mentioned techniques used in NetBricks for isolation are referred to as ZCSI (Zero-Copy Soft Isolation) \cite{Panda2016}. NetBricks runs as a single process, that can be assigned to one or more cores for processing and use one or more NICs for packets I/O. Packets are transferred between network functions using “function calls”, In the case of network function chains, a queue is maintained at the receiving end.
\subsubsection*{Placement and Scheduling}
As mentioned before NetBricks operates as a single process in which many network functions can be run. Consider the network function chains running as a directed graph having access to multiple available NIC interfaces. Before implementing, NetBricks have to decide at which core the network chains should be run. Based on this NetBricks make the scheduling decisions for packet processing. As the author mentioned in \cite{Panda2016}, currently NetBricks places all the network functions on a single core to get the maximum performance. For more complex placements, NetBricks make use of "shuffle" operation to process packets across multiple cores. 
In \cite{Panda2016}, author uses the “run-to-completion” scheduling for NetBricks i.e. packets entering NF, it starts processing till it exists. Scheduling is needed when dealing with more than one packet, considering this all packets are added to  “window” operation i.e. receiving and re-arranging till enough packets have been collected and “group by” operation i.e. stack up packets to be processed by branch. NetBricks uses “round-robin” scheduling for these operations. 
\subsection{Testing}
To test and validate the NetBricks, two network functions were re-programmed \cite{Panda2016}. Firstly, the NF that decrements the IP TTL (Time To Live) and drops the packet with TTL zero. Secondly, google’s Maglev\cite{Yaghoubi2012} (i.e. load balancer).
 
For the first example network function is build using NetBricks as shown in fig.2. Network functions are described as a public function in the RUST module. Line 1 of fig.2 shows how the new instance of network function is created using the “ttl\_nf” function. During the network function processing, at line 3 ethernet (MAC) header is parsed from the packet and later at line 4 IP header is parsed from the packet. “Transform” operation is applied on the parsed IP header decrementing the packet’s TTL (line 5). After the computation of packet’s TTL, “Filter” operation is performed that drops the packets having TTL zero (line 9). In the end “Compose” operation at line 12 indicate the end of the description of network function and also allows the chaining of network function. As shown in fig.2, no “Shuffle” operation is applied while defining the network function. By default, NetBricks routes all the packet processing to a single core. Fig.3 shows the code that is used to execute the user-defined functions. “NetbricksContext” is used to execute the user configuration. As mentioned in \cite{Panda2016}, at line 4 pipeline is created that : (a) receives packets from input queue; (b) these packets are forwarded to network function i.e. “ttl\_nf” for processing; (c) later processed packets are again to the same queue. Placement of the pipeline is defined in user configuration.
\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/fig2}
	\caption{NetBricks code for Example NF}
	\cite{Panda2016}
	\label{key2}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/fig3}
	\caption{NetBricks code for Executing Example NF}
	\cite{Panda2016}
	\label{key3}
\end{figure}

For the second example, the author used load balancer (Maglev) network function and tried to implement it using NetBricks. Maglev is responsible for dividing the user requests among the back-end servers. Maglev ensures that: it can be deployed in a replicated cluster for scalability and fault tolerance: splits traffic; and handles failures. Maglev uses a hashing algorithm (i.e. based on a lookup table) to achieve the aims mentioned above \cite{Panda2016}. Fig.4 shows the packet processing and forwarding part of Maglev.  First, the lookup table is created (line 8) and then a cache for recording the backend (line12) that is used to start the instance of Maglev network function. Starting at line 15, the network function is declared. Second, the “Shuffle” operation (line 16) uses the built-in functionality of using a single core. At line 17 ethernet headers are being parsed. Later  “Group by” operation (line18) is performed, it uses the “ipv4\_flow\_hash” built-in function to extract the flow hash i.e. consist of IP header and TCP or UDP header. This hash is used for two purposes: (a) ensuring that the received packet is TCP or UDP ; (b) to find the already assigned backend to flow (line 24) or to assign new backend to flow using a lookup table (line 25). In the end, network functions generate the vector of nodes relevant to the backend, specified by the operation.
\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/fig4}
	\caption{NetBricks code for google's Magvel}
	\cite{Panda2016}
	\label{key4}
\end{figure}   
\subsection{Analysis Tool}
NetBricks network function chains are build using RUST language and mechanism proposed by the author. That is in contradiction with currently available frameworks i.e. OpenMANO etc. These frameworks provide the developer with an interface to manage without knowing the underlying programmability used for building the network functions. Author in \cite{Panda2016} also proposed to use the same interface, as it provides the following advantages: (a) provides many optimization opportunities, currently using the RUST compiler’s optimization for optimizing the chaining code, later LLVM’s link-time optimization \cite{Lattner} can be used to optimize the whole program, improving performance of packet processing; (b) it can be used to execute the complex network function chains and branches.
\section{Framework Evaluation}
\subsection{Testbed}
For evaluating the NetBricks, as mentioned in a \cite{Panda2016} testbed with the following configuration was used: dual-socket servers with Intel Xeon E5-2660 2.6GHz CPUs, each having 10 cores. Each having 120GB of RAM, divided between sockets. Each server was also equipped with Intel XL710 QDA2 40Gb NIC. Hyper-threading was disabled and hardware virtualization was enabled i.e. Intel VT. Servers running Linux kernel 4.6.0-1 and DPDK 16.04 and programming language RUST nightly version. Two virtual switches were used i.e. first Open Vswitch with DPDK (OVS DPDK) \cite{Gross2014} and second SoftNIC \cite{Han:EECS-2015-155}. VMs used were running on KVM connected to a virtual switch with DPDK’s “vhost-user” driver. As per the requirement of DPDK, Docker containers were used with privileged mode and for their connection to a virtual switch, DPDK’s ring PMD driver was used. By default, PMD driver does not allow both virtual switches to copy packets and no packet isolation was observed as network function can modify the packets after they sent it. To achieve isolation the author made few modifications in virtual switches, allowing copying while connecting to containers. Even this copying using DPDK’s PMD driver has higher performance than other approaches i.e. “veth” pair. To test the traffic, the DPDK-based packet generator was used running on a separate server having 40Gb NIC. This server was directly connected to the test server without any intermediate switches. This packet generator server acted as a source and sink. Performance (i.e. throughput and latency) results were collected at the sink.

\subsection{Overheads and Results}
This section describes the overheads imposed by the NetBricks and the results obtained besides these overheads comparing to baseline network functions build using other frameworks. For comparison purposes, both NIC and DPDK were configured the same for NetBricks and baseline network function. In \cite{Panda2016}, the author mentioned few overheads that are as follows: for simple network function; (b) for checking array bounds.

In the case of simple network function, the packet TTL network function was used as shown in fig.2 and explained in the section above. Both NetBricks version and normal version of network function were executed using a single core by send packets of 64 bytes and observed the throughput. The result of both network functions was almost the same as expected by the author. As mentioned in \cite{Panda2016}, after 10 experimental runs, the average throughput observed for baseline network function was 23.3 MPPS (million packets per second) whereas for NetBricks network function it was observed 23.2 MPPS.  For latency at 80\%, the RTT (round trip time) for baseline observed was 16.15 microseconds compared to NetBricks was 16.16 microseconds.

\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/fig5}
	\caption{Throughput comparison between NetBricks NF and Basline NF}
	\cite{Panda2016}
	\label{key5}
\end{figure}

In the case of array accesses \cite{Panda2016}, the safe language was used that imposed some overheads i.e. array bound checking. These checks can be a major source of the overhead of safe language (i.e. Null-checks and other safety checks performed at runtime are difficult to separate). To test these checks overhead, NF was used that updates several cells in a 512KB array during packet processing. The update of these array cells depends on a UDP source port number of the packet under processing, making it difficult to ignore array bound checks. The author compared the NetBricks NF with a baseline NF executed using a single-core and used packets with random UDP source port. Fig.5 graph shows the throughput achieved by two network functions when memory accesses per packet increased. NetBrick’s throughput is 20\% less as compared to the baseline NF for 1 to 8 memory accesses. As the number of accesses increased i.e. 16 or more, the effect of checks overhead started to fade out. This is because of large memory accesses causing cache misses resulting in reduced throughput. These cache misses dominating the overhead imposed by the NetBricks.    


\subsection{Performance analysis of framework based different NFs}
To further validate the development model of NetBricks, the author implemented different categories of network functions using the NetBricks framework. Some of them are mentioned below\cite{Panda2016}:
\newline
\textbf{Firewall:} based on Click \cite{Martins2014}, performs the linear scan of an ACL (Access Control List) to find the relevant entry.
\newline
\textbf{NAT:} based on MazuNAT [ref] built using Click.
\newline
\textbf{IDS:} based on Snort \cite{Roesch}, for signature matching.
\newline
\textbf{Monitor:} maintains per-flow counter similar to monitor module of Click.
\newline
\textbf{Load balancer:} Maglev used, already described in the above section.
\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/tab1}
	\caption{Performance figures of NetBricks NF w.r.t other NFs}
	\cite{Panda2016}
	\label{key6}
\end{figure}

Testing of the above-mentioned network functions was done using both NetBricks framework and original network function. These network functions were executed on a single core. Comparison results can be seen in fig.6, NetBricks performance is better as compared to other frameworks. For example, as mentioned in \cite{Panda2016} NetBricks NAT has a 3x better performance than MazuNAT. 

Further experiments were performed on the NetBricks version of Maglev to be tested on multi-core. Fig.7 show the comparison of NetBricks version of Maglev with google’s Maglev. It was observed that NetBricks throughput is  2.9x to 3.5x better than the results mentioned in \cite{Yaghoubi2012}. Average latency observed was 19.9 microsecond for NetBricks and 32 microseconds for the original Maglev. These throughput and latency figures are better but not to rely on because these two experiments (i.e. NetBrick’s Maglev version and Google’s Maglev) were performed on two different test-bed.    
\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/tab2}
	\caption{Throughput achieved comparing NetBricks Multi-core with Maglev}
	\cite{Panda2016}
	\label{key7}
\end{figure}
\subsection{Isolation Analysis}
Isolation is ensured by NetBrick’s safe language and runtime checks to avoid costs associated with core boundaries and crossing process \cite{Panda2016}. The author first checked the cost involved with the single network function. Evaluation was done to check the results when the length of the packet TTL NF chain increases. One point to consider here is that these costs are only applicable for simple network functions, but when the computational cost of network function is higher then NetBricks execution environment becomes irrelevant.
\subsubsection*{NF vs NF Chains vs Complex NF}
\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/fig6}
	\caption{VM/Container execution environment for simple NF}
	\cite{Panda2016}
	\label{key8}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/fig7}
	\caption{NetBricks execution environment for simple NF}
	\cite{Panda2016}
	\label{key9}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/fig8}
	\caption{Throughput achieved using different isolation techniques}
	\cite{Panda2016}
	\label{key10}
\end{figure}
This section presents the analysis for single NF, NF chain and complex NF in term of isolation and for that author compared the NetBricks with VMs or Containers \cite{Panda2016}. 

First case, single NF (i.e. “that swaps the source and destination ethernet address for received packets and forward them out the same port”) built using NetBricks and other with C language were compared and executed in their execution environment i.e. VM, Container, and NetBricks. Fig.8 shows the test environment of VM and Container. A vSwitch is used that receives packets from NIC and forward them to network function running in either VM or Container. Network function process those packets and forward them back to vSwitch, which is then forwarded to NIC. Both vSwitch and network function runs on DPDK and depend upon polling. For better performance network function is assigned its dedicated CPU and two cores are assigned to vSwitch. As mentioned in \cite{Panda2016}, with isolation comes two kinds of overheads: first due to cache and context switching cost (i.e. cost associated with cross process or crossing core boundaries) and second due to the copying of packets. To analyze these isolation overheads, the author used SoftNIC to send packets between Containers without copying (i.e. 0-copy SoftNIC Container) violating packet isolation, later compared it with NetBricks. As shown in fig.9, NetBricks receives packets directly from NIC, process them using network function code and send them back to NIC, all this process runs on a single-core. Fig.10 graph shows the throughput achieved using different isolation techniques. As discussed in \cite{Panda2016} Comparison of 0-copy SoftNIC Container and NetBricks concerning throughput shows that 0-copy SoftNIC Container is 1.6x slower then NetBricks due to crossing core boundaries. Even though NetBricks was running on single-core and other was using three cores for processing. SoftNIC Container is 2.7x slower than NetBricks due to packet copying. This performance further degrades when using VM instead of Containers. Because VM uses the “vhost\_user” communication channel developed by DPDK from interacting with VM has more performance issues as compared to DPDK’s ring PMD driver used for Container.
\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/fig9}
	\caption{VM/Container Execution environemt for NF chain}
	\cite{Panda2016}
	\label{key11}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/fig10}
	\caption{NetBricks Execution environemt for NF chain}
	\cite{Panda2016}
	\label{key12}
\end{figure}

Second Case, NF chain (i.e. multiple instances of single network function, compute packet’s TTL (time to live) and drops the packet with TTL 0). Fig.11 shows the execution environment using VM or Container to run the network function chain (i.e. NF0 and NF1). Assigned two cores to vSwitch and two cores for network function chain, one for each network function. Fig.12 shows the execution environment of NetBricks to run the network function chain (i.e. NF0 and NF1). NetBricks was tested for two cases: (a) with single-core; (b) with two-cores. Fig.13 shows the throughput comparison of NetBricks with single-core, multi-core, VM and Container. As mentioned in \cite{Panda2016}, NetBricks multi-core (NB-MC) is 7x better than a container with SoftNIC and 11x better compared to VM with SoftNIC. NetBricks with single-core (NB-SC) is 4x better than a container with SoftNIC and 6x better compared to VM with SoftNIC. The author also compared the 0-copy SoftNIC container and observed that with a packet size of 64 Bytes, it resulted in 3x times performance loss. As shown in fig.13, NetBricks multi-core throughput decreased when the size of the chain increased from 4. The author explained this decrease in throughput is due to more cores tries to accesses the NIC (i.e. 4 parallel I/O threads). Above throughput figures are for a packet size of 64 Bytes. Increasing the packet size degrades the performance by 15\% \cite{Panda2016}. Fig.14 shows the latency when using different isolation techniques.
\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/fig11}
	\caption{Throughput of increasing NF chain, NetBricks single and multi core vs other technologies}
	\cite{Panda2016}
	\label{key13}
\end{figure}

Third case, complex NF (i.e. increases computation cycles for per-packet processing) and used the same execution environment as the first case (i.e. fig.8 and 9). Three core for VM and Container (i.e. one for network function and two for vSwitch) and in case NetBriciks two cases: single-core and three-cores. The author modified the network function to use busy loops for the number of cycles after packet processing. Fig.12 shows the throughput comparison of per-packet processing by using different isolation techniques. As mentioned in \cite{Panda2016}, increasing complexity of network function results in increased computation time that overcomes the improvements offered by NetBricks (i.e. 300 cycles per packet). As shown in fig.15, NetBricks isolation performs better as compared to other techniques (i.e. VM or Container). 
\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/fig12}
	\caption{Latency for increasing NF chain, NetBricks single/multi-core vs other technologies}
	\cite{Panda2016}
	\label{key14}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/fig13}
	\caption{Throughput of Complex NF using different isolation techniques}
	\cite{Panda2016}
	\label{key15}
\end{figure}
\section{Comparison of Frameworks}
In this section, NetBricks is compared with other frameworks available in the market. A comparison is done based on the development model, execution model, and isolation.
\subsection{Development Model}
In terms of development model, there are many frameworks available such as YANFF \cite{Philippov2017} helps in rapid network function development. It is based on DPDK and uses GO language that is high-level, safe with built-in support for concurrency. YANFF uses the scheduler for packet processing across multiple cores, whereas in NetBricks it is done by explicit “shuffle” operations. YANFF has no dependencies on the execution environment. Next is libVNF \cite{Naik2017}, a reusable library for developing high performance and scalable network functions. An API is used, that provides the high-level abstraction and manages low-level optimization. It separates the application-specific processing of network functions from the software stack that can be reusable or common for all network functions. Compared to NetBricks, libVNF supports clustered network functions deployment and horizontal scalability (i.e. ensuring high availability). FLICK \cite{Abdul} framework for development and deployment of network functions. FLICK structure is quite similar to NetBricks, both use their own programming languages for development and have their own execution environment to run the developed network functions. FLICK language allows to focus on only application-specific logic ignoring low-level details. Developed network function is compiled using the FLICK compiler that converts the FLICK program into C++, which is then compiled and linked with FLICK runtime for execution.
\subsection{Execution Model}
In terms of the execution model, NetVM \cite{Hwang2015} is a virtualization-based platform that uses shared memory to exploit the DPDK library (i.e. ensuring 0-copy between VMs and to VMs). It uses the hypervisor-based switch to control the flow of packets and inter-VM communication. Also, ensure isolation to some extent i.e. packet accesses to only trusted VMs. OpenNetVM \cite{Yurchenko2018} is based on the NetVM framework, it uses Docker Container instead of VM. OpenNetVM consists of two main components: first, NF Manager that interact with NICs and responsible for packet flow management and inter-container communication. Second NFlib API that is used to connect network function (i.e. container) to NF Manager, it also allows the development of user-defined network function and makes use of NFlib to connect with NF Manager. HyperNF \cite{Yasukata2017} is VM based framework, fully utilizing the available resources (i.e. CPU cores). No dedicated cores assigned for packet I/O as per the merge model \cite{Yasukata2017} and packet I/O are part of VM. It uses “hypercall” instead of packet forwarding and communication between VMs. Compared to NetBricks, HyperNF is based on standard NFV architecture whereas NetBricks completely rewrites the software middleboxes. G-NET \cite{Zhang2018} framework is based on GPU-virtualization. It consists of three main components: “Switch” is a virtual switch for packet I/O and forwarding packets between network functions; “Manager” is proxy for GPU, it receives a request from network function for GPU computation; “Scheduler” allocates the GPU resources. G-NET also ensure the data isolation by using “isoPointer”.
\subsection{Isolation}
In terms of Isolation, SafeBricks \cite{Poddar2018} framework is based on NetBricks with some modifications. It is more oriented to cloud security. It ensures only encrypted traffic is exposed to the cloud. SafeBricks used the concept of “hardware enclave” using Intel SGX [ref] (i.e. ensures that software even kernel or hypervisor outside the enclave cannot tamper with enclave). It allows the network function to run inside the enclave and in the cloud, it seems like a black box. Fig.16 shows the author’s comparison of the different framework (i.e. xOMB\cite{Anderson2012}, CoMB\cite{Sekar}, ClickOS\cite{Martins2014}, HyperSwitch\cite{Ram2013}, mSwitch\cite{Honda2015}) in context with isolation.
\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/fig14}
	\caption{Isolation between different frameworks}
	\cite{Panda2016}
	\label{key16}
\end{figure}
\section{Future Work}
Future work of the NetBricks framework should be optimizing the RUST language to remove the overhead of the NetBricks framework. Currently, it supports multi-core processing, but further optimizations can be done to get even better throughput. Maintain the active development of new network functions and provide support. Currently, NetBricks works on the data plane and control plane functionality should be added in the future to get better performance. Lastly, the integration with MANO systems.
\label{sec:conclusion}




\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,main}

% that's all folks
\end{document}
